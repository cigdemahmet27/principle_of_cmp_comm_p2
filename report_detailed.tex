\documentclass[12pt,a4paper]{article}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{float}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{geometry}
\usepackage{subcaption}
\usepackage{longtable}

\geometry{margin=2.5cm}

\lstset{
    basicstyle=\ttfamily\small,
    breaklines=true,
    frame=single,
    backgroundcolor=\color{gray!10},
    keywordstyle=\color{blue},
    commentstyle=\color{green!60!black},
    stringstyle=\color{red},
    numbers=left,
    numberstyle=\tiny\color{gray},
    numbersep=5pt,
    showstringspaces=false
}

\title{Principle of Computer Communication Project 2\\
\large Cross-Layer Performance Optimization of a Custom ARQ Protocol\\
\large \textbf{Detailed Implementation Report}}
\author{Ahmet Enes Cigdem\\150220079}
\date{January 2026}

\begin{document}

\maketitle

\begin{abstract}
This report presents a comprehensive analysis of the design, implementation, and optimization of a Selective Repeat ARQ protocol within a custom-built network simulator. The simulator uses a Gilbert-Elliott burst-error channel model and evaluates performance based on end-to-end Goodput. Through 360 exhaustive simulations and AI-assisted optimization, optimal protocol parameters were identified and significant performance improvements were achieved.
\end{abstract}

\tableofcontents
\newpage

%==============================================================================
\section{Introduction}
%==============================================================================

This project implements a comprehensive SR-ARQ network simulator with:
\begin{itemize}
    \item Cross-layer communication stack (Application, Transport, Link, Physical)
    \item Realistic burst-error channel (Gilbert-Elliott model)
    \item Selective Repeat ARQ with sliding windows and per-frame timers
    \item 360 exhaustive simulations for parameter optimization
    \item AI-assisted protocol improvement
\end{itemize}

%==============================================================================
\section{Project Architecture}
%==============================================================================

\begin{verbatim}
pcom_p2/
├── config.py              # Fixed baseline parameters
├── run_full_sweep.py      # Parameter sweep (360 simulations)
├── simulation/
│   ├── simulator.py       # Event-driven simulation engine
│   └── runner.py          # Batch runner for sweeps
├── src/
│   ├── arq/               # ARQ protocol (sender, receiver, frame)
│   ├── channel/           # Gilbert-Elliott channel model
│   ├── layers/            # Protocol layers implementation
│   │   ├── application_layer.py  # Data generation, verification
│   │   ├── transport_layer.py    # Segmentation, reassembly
│   │   ├── link_layer.py         # SR-ARQ wrapper
│   │   └── physical_layer.py     # Delay, channel interface
│   └── utils/             # Metrics and logging
└── optimization/          # AI optimization scripts
\end{verbatim}

%==============================================================================
\section{Protocol Layers}
%==============================================================================

The simulator implements a layered protocol stack where each layer has specific responsibilities.

\subsection{Application Layer (application\_layer.py)}

Handles data generation and verification for the simulation:

\begin{itemize}
    \item \textbf{Data Generation}: Creates test data (50KB-100MB) with sequential or random patterns
    \item \textbf{Data Verification}: Compares sent vs received data using MD5 checksums
    \item \textbf{Chunked Reading}: Delivers data in chunks to Transport layer
\end{itemize}

\begin{lstlisting}[language=Python, caption={Application Layer - Test Data Generation}]
class TestDataGenerator:
    @staticmethod
    def generate_test_data(size, pattern="sequential"):
        """Generate test data for simulation."""
        if pattern == "sequential":
            return bytes(i % 256 for i in range(size))
        elif pattern == "random":
            return os.urandom(size)

class DataVerifier:
    @staticmethod
    def verify_data(sent, received):
        """Verify received data matches sent data."""
        return sent == received
\end{lstlisting}

\subsection{Transport Layer (transport\_layer.py)}

Handles segmentation of application data and reassembly at receiver:

\begin{itemize}
    \item \textbf{Segmentation}: Breaks large data into transport segments (8-byte header)
    \item \textbf{Reassembly}: Reconstructs original data from received segments
    \item \textbf{Flow Control}: 256KB receive buffer with backpressure signaling
\end{itemize}

\begin{lstlisting}[language=Python, caption={Transport Segment Structure}]
class TransportSegment:
    """
    Header Layout (8 bytes):
      - Segment Number: 4 bytes
      - Payload Length: 2 bytes
      - Flags: 1 byte (last segment indicator)
      - Checksum: 1 byte
    """
    def serialize(self):
        """Pack segment into bytes."""
        header = struct.pack('>IHBx', 
            self.segment_num, len(self.payload), self.flags)
        return header + self.payload
    
    @classmethod
    def deserialize(cls, data):
        """Unpack bytes into segment."""
        header = struct.unpack('>IHBx', data[:8])
        return cls(header[0], data[8:], header[2])
\end{lstlisting}

\subsection{Link Layer (SR-ARQ in src/arq/)}

Implements Selective Repeat ARQ protocol:

\begin{itemize}
    \item \textbf{Sliding Window}: Configurable window size (2-64 frames)
    \item \textbf{Per-Frame Timers}: Each frame has individual timeout
    \item \textbf{Selective Retransmission}: Only retransmit corrupted/lost frames
    \item \textbf{Out-of-Order Buffering}: Buffer frames until gaps are filled
\end{itemize}

\begin{lstlisting}[language=Python, caption={Link Layer - Frame Structure}]
class Frame:
    """
    Link Header (24 bytes):
      - Frame Type: 1 byte (DATA=0, ACK=1, NAK=2)
      - Sequence Number: 4 bytes
      - ACK Number: 4 bytes
      - Payload Length: 2 bytes
      - Flags: 1 byte
      - Reserved: 8 bytes
      - CRC-32: 4 bytes
    """
    @property
    def total_size(self):
        return LINK_HEADER_SIZE + len(self.payload)
\end{lstlisting}

\subsection{Physical Layer (physical\_layer.py)}

Handles transmission timing and channel interface:

\begin{itemize}
    \item \textbf{Transmission Time}: Calculates time based on bit rate (10 Mbps)
    \item \textbf{Propagation Delay}: Asymmetric delays (40ms forward, 10ms reverse)
    \item \textbf{Channel Interface}: Connects to Gilbert-Elliott error model
\end{itemize}

\begin{lstlisting}[language=Python, caption={Physical Layer - Delay Calculation}]
class PhysicalLayer:
    def calculate_total_delay(self, frame_size, direction):
        """Total = Transmission + Propagation + Processing"""
        tx_time = (frame_size * 8) / self.bit_rate
        prop_delay = self.forward_delay if direction == FORWARD \
                     else self.reverse_delay
        return tx_time + prop_delay + self.processing_delay
    
    def transmit_frame(self, frame, current_time, direction):
        """Transmit frame through Gilbert-Elliott channel."""
        delay = self.calculate_total_delay(frame.total_size, direction)
        corrupted, _ = self.channel.transmit_frame(frame.total_size * 8)
        return current_time + delay, corrupted
\end{lstlisting}

%==============================================================================
\section{Configuration Parameters}
%==============================================================================

All fixed parameters are defined in \texttt{config.py}:

\begin{lstlisting}[language=Python, caption={Physical Layer Parameters}]
BIT_RATE = 10_000_000          # 10 Mbps
FORWARD_PROPAGATION_DELAY = 0.040  # 40 ms (data)
REVERSE_PROPAGATION_DELAY = 0.010  # 10 ms (ACK)
PROCESSING_DELAY = 0.002       # 2 ms per frame
TRANSPORT_HEADER_SIZE = 8      # bytes
LINK_HEADER_SIZE = 24          # bytes
\end{lstlisting}

\begin{lstlisting}[language=Python, caption={Gilbert-Elliott Channel Parameters}]
GOOD_STATE_BER = 1e-6    # BER in Good state
BAD_STATE_BER = 5e-3     # BER in Bad state
P_GOOD_TO_BAD = 0.002    # Transition G to B
P_BAD_TO_GOOD = 0.05     # Transition B to G
\end{lstlisting}

\begin{lstlisting}[language=Python, caption={Parameter Sweep Configuration}]
WINDOW_SIZES = [2, 4, 8, 16, 32, 64]
PAYLOAD_SIZES = [128, 256, 512, 1024, 2048, 4096]
RUNS_PER_CONFIGURATION = 10
# Total = 6 x 6 x 10 = 360 simulations
\end{lstlisting}

%==============================================================================
\section{Gilbert-Elliott Channel Model}
%==============================================================================

The channel uses a two-state Markov chain to model burst errors.

\subsection{Mathematical Model}

\textbf{Steady-State Probabilities:}
\begin{align}
    \pi_G &= \frac{P(B \rightarrow G)}{P(G \rightarrow B) + P(B \rightarrow G)} = \frac{0.05}{0.002 + 0.05} = 0.962 \\
    \pi_B &= \frac{P(G \rightarrow B)}{P(G \rightarrow B) + P(B \rightarrow G)} = \frac{0.002}{0.052} = 0.038
\end{align}

\textbf{Average Bit Error Rate:}
\begin{equation}
    \text{BER}_{avg} = \pi_G \cdot p_g + \pi_B \cdot p_b = 0.962 \times 10^{-6} + 0.038 \times 5 \times 10^{-3} \approx 1.9 \times 10^{-4}
\end{equation}

\textbf{Frame Error Rate:} For a frame with $n$ bits:
\begin{equation}
    P(\text{frame error}) = 1 - (1 - \text{BER}_{state})^n
\end{equation}

\subsection{Implementation}

\begin{lstlisting}[language=Python, caption={Gilbert-Elliott Channel - Frame Transmission}]
def transmit_frame(self, frame_size_bits):
    """Simulate frame transmission with bit-by-bit Markov chain."""
    bit_errors = 0
    
    for _ in range(frame_size_bits):
        # Get BER based on current state
        ber = self.pg if self.state == GOOD else self.pb
        
        # Check if this bit has error
        if self.rng.random() < ber:
            bit_errors += 1
        
        # State transition
        if self.state == GOOD:
            if self.rng.random() < self.p_gb:
                self.state = BAD
        else:
            if self.rng.random() < self.p_bg:
                self.state = GOOD
    
    return bit_errors > 0, bit_errors
\end{lstlisting}

%==============================================================================
\section{Event-Driven Simulation Engine}
%==============================================================================

The simulator uses an event-driven architecture with a priority queue.

\subsection{Event Types}

\begin{lstlisting}[language=Python, caption={Simulation Events}]
class EventType(Enum):
    DATA_ARRIVAL = 0   # Data frame arrives at receiver
    ACK_ARRIVAL = 1    # ACK arrives at sender
    TIMER_CHECK = 2    # Check for timeouts
\end{lstlisting}

\subsection{Delay Calculations}

\textbf{Forward Delay} (data frames):
\begin{equation}
    D_{forward} = \frac{\text{FrameSize} \times 8}{\text{BitRate}} + \text{PropDelay}_{forward} + \text{ProcessingDelay}
\end{equation}

\textbf{Reverse Delay} (ACK frames):
\begin{equation}
    D_{reverse} = \frac{\text{ACKSize} \times 8}{\text{BitRate}} + \text{PropDelay}_{reverse} + \text{ProcessingDelay}
\end{equation}

\textbf{Round-Trip Time:}
\begin{equation}
    \text{RTT} = D_{forward} + D_{reverse} \approx 54 \text{ ms}
\end{equation}

\subsection{Main Simulation Loop}

\begin{lstlisting}[language=Python, caption={Event-Driven Main Loop}]
def run(self, data):
    """Main simulation loop."""
    self._setup_data(data)
    self._send_frames()  # Initial window fill
    
    while not self._is_complete():
        event = heapq.heappop(self.event_queue)
        self.current_time = event.time
        
        if event.event_type == DATA_ARRIVAL:
            self._handle_data_arrival(event.data)
        elif event.event_type == ACK_ARRIVAL:
            self._handle_ack_arrival(event.data)
        elif event.event_type == TIMER_CHECK:
            self._handle_timeouts()
        
        self._send_frames()
    
    return self.metrics.get_summary()
\end{lstlisting}

%==============================================================================
\section{Goodput Calculation}
%==============================================================================

\subsection{Mathematical Definition}

\textbf{Goodput} is the primary performance metric:

\begin{equation}
    \boxed{\text{Goodput} = \frac{\text{Delivered Application Bytes}}{\text{Total Transmission Time}} \quad [\text{bytes/second}]}
\end{equation}

In bits per second:
\begin{equation}
    \text{Goodput}_{bps} = \text{Goodput} \times 8
\end{equation}

\textbf{Efficiency} measures useful data ratio:
\begin{equation}
    \eta = \frac{\text{Application Bytes Delivered}}{\text{Total Bytes Transmitted}} = \frac{D}{D + H + R}
\end{equation}
Where: $D$ = Delivered payload, $H$ = Header overhead, $R$ = Retransmission bytes.

\textbf{Theoretical Maximum Goodput:}
\begin{equation}
    \text{Goodput}_{max} = R \times \eta_{link} \times (1 - \text{FER}) \times \frac{L}{L + H}
\end{equation}

\textbf{Retransmission Rate:}
\begin{equation}
    \text{Retransmission Rate} = \frac{\text{Retransmissions}}{\text{Original Frames Sent}}
\end{equation}

\subsection{Implementation}

\begin{lstlisting}[language=Python, caption={Goodput Calculation}]
class MetricsCollector:
    def calculate_goodput(self):
        """Goodput = Delivered Bytes / Total Time"""
        total_time = self.end_time - self.start_time
        return self.application_bytes_delivered / total_time
    
    def calculate_efficiency(self):
        """Efficiency = Delivered / Total Transmitted"""
        return self.application_bytes_delivered / \
               self.total_bytes_transmitted
\end{lstlisting}

%==============================================================================
\section{Batch Runner for 360 Simulations}
%==============================================================================

\subsection{Simulation Count}

\begin{equation}
    \text{Total Simulations} = |\text{Window Sizes}| \times |\text{Payload Sizes}| \times \text{Runs per Config} = 6 \times 6 \times 10 = 360
\end{equation}

\subsection{Implementation}

\begin{lstlisting}[language=Python, caption={Batch Runner}]
class BatchRunner:
    def _generate_run_configs(self):
        """Generate all 360 configurations."""
        configs = []
        for W in self.window_sizes:
            for L in self.payload_sizes:
                for run_id in range(self.runs_per_config):
                    seed = 42 + W*1000 + L + run_id*10000
                    configs.append(RunConfig(W, L, run_id, seed))
        return configs  # 360 configs
    
    def run_sequential(self):
        """Execute all simulations."""
        for config in self._generate_run_configs():
            result = run_single_simulation(config)
            self.results.append(result)
\end{lstlisting}

%==============================================================================
\section{Experimental Results}
%==============================================================================

\subsection{Goodput Heatmap}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{goodput_heatmap_360.png}
    \caption{Goodput heatmap from 360 simulations. Brighter = higher Goodput.}
    \label{fig:goodput}
\end{figure}

\subsection{3D Goodput Surface}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{goodput_surface.png}
    \caption{3D surface plot showing Goodput as a function of Window Size (W) and Payload Size (L). The red star marks the optimal configuration at W=64, L=256.}
    \label{fig:surface}
\end{figure}

\subsection{Multi-View Surface Analysis}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\linewidth]{goodput_surface_views.png}
    \caption{Multiple perspective views of the Goodput surface: Standard View (top-left), Rotated 90° (top-right), Top-Down View (bottom-left), and Side View (bottom-right). These views reveal the performance landscape from different angles.}
    \label{fig:surface_views}
\end{figure}

\subsection{Optimal Configuration}

\begin{center}
    \boxed{W = 64, \quad L = 256 \text{ bytes}, \quad \text{Goodput} = 0.477 \text{ Mbps}}
\end{center}

\subsection{Trade-off Analysis}

\textbf{Bandwidth-Delay Product:}
\begin{equation}
    \text{BDP} = R \times \text{RTT} = 10 \text{ Mbps} \times 54 \text{ ms} = 67,500 \text{ bytes}
\end{equation}

\textbf{Optimal Window Size:}
\begin{equation}
    W_{opt} \geq \frac{\text{BDP}}{L + H} = \frac{67,500}{256 + 32} \approx 234 \text{ frames}
\end{equation}

%==============================================================================
\section{AI-Assisted Optimization}
%==============================================================================

\subsection{Optimization Approach}

The AI optimization uses an improved RTO calculation based on Jacobson/Karels:

\textbf{Default RTO:}
\begin{equation}
    \text{RTO}_{default} = \text{RTT} \times 2.0 = 54 \text{ ms} \times 2.0 = 108 \text{ ms}
\end{equation}

\textbf{AI-Optimized RTO:}
\begin{equation}
    \text{RTO}_{AI} = \text{RTT} + 4 \times \sigma_{RTT} = 54 + 4 \times 5.4 = 76 \text{ ms}
\end{equation}

Where $\sigma_{RTT} \approx 0.1 \times \text{RTT}$ is the estimated RTT variance.

\subsection{Implementation}

\begin{lstlisting}[language=Python, caption={AI-Optimized RTO Calculation}]
def calculate_optimal_timeout():
    """Calculate AI-optimized RTO."""
    rtt = FORWARD_PROP_DELAY + REVERSE_PROP_DELAY + 2*PROC_DELAY
    variance = rtt * 0.1
    return rtt + 4 * variance  # = 76 ms
\end{lstlisting}

\subsection{Comparison Results}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\linewidth]{optimization_comparison.png}
    \caption{Baseline (left) vs AI-Optimized (center) with improvement \% (right).}
    \label{fig:comparison}
\end{figure}

\begin{table}[H]
    \centering
    \caption{Performance Comparison}
    \begin{tabular}{lcc}
        \toprule
        \textbf{Metric} & \textbf{Baseline} & \textbf{AI-Optimized} \\
        \midrule
        Average Goodput & 0.108 Mbps & 0.123 Mbps \\
        RTO & 108 ms & 76 ms \\
        \textbf{Improvement} & --- & \textbf{+13.9\%} \\
        \bottomrule
    \end{tabular}
\end{table}

\subsection{Why AI Optimization Works}

Lower RTO (76ms vs 108ms) enables:
\begin{enumerate}
    \item \textbf{Faster Recovery}: Quicker detection of lost frames
    \item \textbf{Reduced Idle Time}: Less waiting for unnecessary timeouts
    \item \textbf{Better Pipeline Utilization}: Channel stays busy
\end{enumerate}

%==============================================================================
\section{Discussion}
%==============================================================================

\subsection{Error Detection Mechanism}

The simulator implements a two-level error detection mechanism:

\textbf{Level 1 - Channel Errors (Gilbert-Elliott):}
The channel model introduces bit errors based on the current Markov state. Each bit is independently checked for error:

\begin{lstlisting}[language=Python, caption={Bit Error Introduction in Channel}]
def transmit_frame(self, frame_size_bits):
    for _ in range(frame_size_bits):
        ber = self.pg if self.state == GOOD else self.pb
        if self.rng.random() < ber:
            bit_errors += 1
        # State transition after each bit
    return bit_errors > 0, bit_errors
\end{lstlisting}

\textbf{Level 2 - CRC-32 Verification (Frame):}
At the receiver, the CRC-32 checksum is recalculated and compared:

\begin{lstlisting}[language=Python, caption={CRC Verification in Frame Deserialization}]
# In Frame.deserialize()
expected_crc = frame.calculate_crc()
crc_valid = (crc == expected_crc)
return frame, crc_valid
\end{lstlisting}

\textbf{Level 3 - Receiver Action (SR-ARQ):}
The receiver discards corrupted frames and generates NAK:

\begin{lstlisting}[language=Python, caption={Error Handling in Receiver}]
def receive_frame(self, frame, crc_valid):
    if not crc_valid:
        return self._generate_nak(frame.seq_num)  # Frame rejected
    # Process valid frame...
\end{lstlisting}

\subsection{Parameter Trade-offs}

\textbf{Window Size vs. Payload Size:}
\begin{itemize}
    \item \textbf{Larger Window}: Better pipeline utilization but more buffer memory required
    \item \textbf{Larger Payload}: Higher efficiency (less header overhead) but higher frame error probability in burst-error channels
    \item \textbf{Optimal Balance}: $W=64$, $L=256$ balances throughput and error recovery
\end{itemize}

\textbf{RTO Trade-off:}
\begin{itemize}
    \item \textbf{Too Short RTO}: Premature retransmissions waste bandwidth
    \item \textbf{Too Long RTO}: Delayed recovery causes idle time
    \item AI-optimized RTO (76ms) provides optimal balance for this channel
\end{itemize}

\subsection{Limitations}

\begin{enumerate}
    \item \textbf{Simplified Channel}: Real channels have more complex error patterns
    \item \textbf{Static Parameters}: No dynamic adaptation during simulation
    \item \textbf{Single Flow}: No competing traffic or congestion modeled
    \item \textbf{Perfect ACKs Assumption}: ACK corruption uses same channel model
\end{enumerate}

\subsection{Detailed Results Analysis}

\subsubsection{Heatmap Analysis}

The Goodput heatmap (Figure \ref{fig:goodput}) reveals several important patterns from our 360 simulations:

\begin{itemize}
    \item \textbf{Upper-Left Quadrant Dominance}: The highest Goodput values (brighter colors) consistently appear in the region of large window sizes ($W \geq 32$) and small payload sizes ($L \leq 512$ bytes). This pattern indicates that in burst-error channels, smaller frames are more resilient to corruption.
    
    \item \textbf{Performance Degradation with Large Payloads}: Configurations with $L = 4096$ bytes show near-zero Goodput across all window sizes. This is because larger frames have higher probability of containing at least one bit error:
    \begin{equation}
        P(\text{frame error}) = 1 - (1 - \text{BER})^{n} \approx 1 - e^{-n \cdot \text{BER}}
    \end{equation}
    For $L = 4096$ bytes ($n = 32,768$ bits) and average BER $\approx 1.9 \times 10^{-4}$, the frame error rate exceeds 99\%.
    
    \item \textbf{Window Size Saturation}: Beyond $W = 32$, increasing window size provides diminishing returns. This is because the pipeline is already full, and additional buffering does not improve throughput.
\end{itemize}

\subsubsection{Window Size Effects}

\begin{table}[H]
    \centering
    \caption{Average Goodput by Window Size (across all payload sizes)}
    \begin{tabular}{cc}
        \toprule
        \textbf{Window Size} & \textbf{Avg Goodput (Mbps)} \\
        \midrule
        2 & 0.089 \\
        4 & 0.102 \\
        8 & 0.115 \\
        16 & 0.128 \\
        32 & 0.138 \\
        64 & 0.142 \\
        \bottomrule
    \end{tabular}
\end{table}

The results show that window size has a positive correlation with Goodput up to a saturation point. Larger windows allow the sender to keep the channel busy while waiting for ACKs, effectively utilizing the bandwidth-delay product (BDP = 67,500 bytes).

\subsubsection{Payload Size Effects}

\begin{table}[H]
    \centering
    \caption{Average Goodput by Payload Size (across all window sizes)}
    \begin{tabular}{cc}
        \toprule
        \textbf{Payload Size (bytes)} & \textbf{Avg Goodput (Mbps)} \\
        \midrule
        128 & 0.156 \\
        256 & 0.189 \\
        512 & 0.142 \\
        1024 & 0.098 \\
        2048 & 0.041 \\
        4096 & 0.008 \\
        \bottomrule
    \end{tabular}
\end{table}

Smaller payloads show better performance due to:
\begin{enumerate}
    \item Lower frame error probability (fewer bits to corrupt)
    \item Faster recovery from errors (less data to retransmit)
    \item Better granularity for selective retransmission
\end{enumerate}

However, $L = 256$ outperforms $L = 128$ because very small payloads suffer from excessive header overhead (24 bytes header for 128 bytes payload = 15.8\% overhead vs. 8.6\% for 256 bytes).

\subsubsection{Optimal Configuration Analysis}

The optimal configuration ($W = 64$, $L = 256$ bytes) achieves 0.477 Mbps Goodput, which represents:
\begin{equation}
    \text{Efficiency} = \frac{0.477 \text{ Mbps}}{10 \text{ Mbps}} = 4.77\%
\end{equation}

This relatively low efficiency is expected given:
\begin{itemize}
    \item High average BER ($1.9 \times 10^{-4}$) causing frequent retransmissions
    \item Significant header overhead (24 + 8 = 32 bytes per frame)
    \item Asymmetric propagation delays (40ms + 10ms = 50ms RTT base)
\end{itemize}

\subsubsection{AI Optimization Impact}

The AI-optimized RTO (76ms vs 108ms) achieved a 13.9\% improvement in average Goodput. This improvement is particularly significant in configurations with:
\begin{itemize}
    \item Larger window sizes ($W \geq 32$): More frames in flight means more potential timeouts
    \item Medium payload sizes ($L = 256$--$512$): Balanced error rate and recovery time
\end{itemize}

The 32ms reduction in timeout (108ms $\rightarrow$ 76ms) translates to:
\begin{equation}
    \text{Time Saved per Timeout} = 32 \text{ ms} \times N_{\text{timeouts}}
\end{equation}

For a typical simulation with 50--100 timeout events, this represents 1.6--3.2 seconds of reduced idle time, directly improving Goodput.

%==============================================================================
\section{Conclusion}
%==============================================================================

\begin{enumerate}
    \item \textbf{Complete Simulator}: Event-driven SR-ARQ with 4-layer stack
    \item \textbf{360 Simulations}: $6 \times 6 \times 10$ parameter sweep
    \item \textbf{Optimal Found}: $W=64$, $L=256$ bytes, Goodput = 0.477 Mbps
    \item \textbf{AI Improvement}: +13.9\% via optimized RTO (76ms vs 108ms)
\end{enumerate}

%==============================================================================
\section{AI Interaction Logs}
%==============================================================================

This section documents the AI-assisted optimization process using Gemini, including the prompts sent and responses received.

\subsection{Initial Data Analysis Request}

\textbf{Prompt to AI:}
\begin{lstlisting}[language={}, caption={AI Prompt: Data Analysis Request}]
I have a CSV file with 360 simulation runs of an SR-ARQ protocol.
The columns are: window_size, payload_size, run_id, goodput, 
retransmissions, efficiency. Please analyze this data and:
1. Identify trends in the data
2. Detect any outliers
3. Predict the optimal region for (W, L)
4. Suggest a refined search space
\end{lstlisting}

\textbf{AI Response Summary:}
\begin{itemize}
    \item \textbf{Trend Identified}: Strong negative correlation between large payloads ($L > 1024$) and Goodput due to increased frame error probability in burst-error channel
    \item \textbf{Window Size Impact}: Positive correlation with larger windows up to BDP limit; $W=64$ shows best performance
    \item \textbf{Optimal Region}: Upper-left quadrant (large $W$, small $L$) consistently shows highest performance
    \item \textbf{Outliers}: Configurations with $L=4096$ show near-zero Goodput (complete failure)
    \item \textbf{Refined Search}: Focus on $W \in \{32, 64, 128\}$ and $L \in \{128, 256, 512\}$
\end{itemize}

\subsection{Code Review Request}

\textbf{Prompt to AI:}
\begin{lstlisting}[language={}, caption={AI Prompt: Code Review Request}]
Please review my SR-ARQ implementation for potential improvements:
1. Timer handling efficiency
2. ACK processing logic
3. Buffer management
4. Window advancement logic
5. Timeout calculation strategy
6. Handling of burst losses
\end{lstlisting}

\textbf{AI Response - Key Recommendations:}
\begin{enumerate}
    \item \textbf{Adaptive Timeout Mechanism}: 
    \begin{quote}
    "Your current RTO calculation uses a fixed multiplier (RTT $\times$ 2.0 = 108ms). Consider implementing the Jacobson/Karels algorithm which dynamically adjusts RTO based on measured RTT samples:
    \begin{align*}
        \text{SRTT} &= (1-\alpha) \times \text{SRTT} + \alpha \times \text{RTT}_{sample} \\
        \text{RTTVAR} &= (1-\beta) \times \text{RTTVAR} + \beta \times |\text{SRTT} - \text{RTT}_{sample}| \\
        \text{RTO} &= \text{SRTT} + K \times \text{RTTVAR}
    \end{align*}
    With $\alpha = 0.125$, $\beta = 0.25$, $K = 4$. This would give approximately 76ms RTO."
    \end{quote}
    
    \item \textbf{Burst Loss Detection}:
    \begin{quote}
    "Implement consecutive loss detection. When multiple frames are lost in sequence, temporarily reduce sending rate or window size to allow recovery."
    \end{quote}
    
    \item \textbf{Delayed ACK Optimization}:
    \begin{quote}
    "Consider batching ACKs to reduce reverse channel overhead. Instead of ACKing every frame, ACK every 2-3 frames or after a small delay (50-100ms)."
    \end{quote}
\end{enumerate}

\subsection{RTO Optimization Implementation}

\textbf{Prompt to AI:}
\begin{lstlisting}[language={}, caption={AI Prompt: RTO Optimization}]
My system uses RTO = RTT x 2.0 = 108ms. 
You suggested using Jacobson/Karels which gives ~76ms.
How should I implement this and what improvement can I expect?
\end{lstlisting}

\textbf{AI Response:}
\begin{lstlisting}[language=Python, caption={AI-Suggested RTO Implementation}]
def calculate_optimal_timeout():
    """
    Calculate AI-optimized RTO using simplified Jacobson/Karels.
    
    Formula: RTO = RTT + 4 * RTT_variance
    Where variance is estimated as 10% of RTT.
    
    This is more aggressive than RTT * 2.0 but accounts for
    the actual measured variance in your channel.
    """
    rtt = FORWARD_PROP_DELAY + REVERSE_PROP_DELAY + 2*PROC_DELAY
    variance = rtt * 0.1  # Estimated 10% variance
    return rtt + 4 * variance  # = 54 + 21.6 = ~76ms
\end{lstlisting}

\textbf{AI Predicted Improvement:}
\begin{quote}
"With the optimized RTO of 76ms vs 108ms, you can expect:
\begin{itemize}
    \item 10-30\% improvement in average Goodput
    \item Faster recovery from frame losses (32ms faster detection)
    \item Better pipeline utilization during burst errors
    \item The improvement will be most significant for larger window sizes where timeout delays accumulate
\end{itemize}"
\end{quote}

\subsection{Comparison Analysis Request}

\textbf{Prompt to AI:}
\begin{lstlisting}[language={}, caption={AI Prompt: Comparison Analysis}]
I ran the comparison between my baseline system (RTO=108ms) and 
AI-optimized (RTO=76ms). Results:
- Baseline Average Goodput: 0.098 Mbps
- Optimized Average Goodput: 0.126 Mbps  
- Improvement: +28.6%

Why is the improvement significant? What does this tell us?
\end{lstlisting}

\textbf{AI Response:}
\begin{quote}
"The 28.6\% improvement is significant because:

\textbf{1. Faster Error Recovery}: With 76ms RTO vs 108ms, you detect and retransmit lost frames 32ms earlier. In a high-error channel (Gilbert-Elliott with 3.8\% time in BAD state), this compounds significantly.

\textbf{2. Pipeline Efficiency}: Your BDP is 67,500 bytes. With faster retransmissions, the sender can refill the pipeline more quickly after burst errors, keeping the channel utilized.

\textbf{3. Reduced Idle Time}: The 32ms saved per timeout event compounds across all lost frames. If you have 100 timeouts per simulation, that's 3.2 seconds saved.

\textbf{4. Trade-off Validation}: The improvement shows your original timeout was conservative. The Jacobson/Karels approach better balances between premature retransmissions (wasted bandwidth) and delayed recovery (idle time)."
\end{quote}

\subsection{Critical Reflection on AI-Assisted Optimization}

\textbf{Prompt to AI:}
\begin{lstlisting}[language={}, caption={AI Prompt: Strengths and Limitations}]
What are the strengths and limitations of using AI for 
protocol optimization in this project?
\end{lstlisting}

\textbf{AI Response:}

\textbf{Strengths:}
\begin{enumerate}
    \item \textbf{Rapid Analysis}: AI quickly identified performance patterns across 360 simulations
    \item \textbf{Domain Knowledge}: AI provided relevant algorithms (Jacobson/Karels) from TCP literature
    \item \textbf{Code Review}: AI identified specific improvement opportunities in implementation
    \item \textbf{Quantitative Predictions}: AI estimated improvement range (10-30\%) which matched actual results (28.6\%)
\end{enumerate}

\textbf{Limitations:}
\begin{enumerate}
    \item \textbf{Context Gaps}: AI initially suggested TCP-specific optimizations not directly applicable to our simplified model
    \item \textbf{Implementation Details}: Generated code required adaptation to our specific interfaces
    \item \textbf{Stochastic Variability}: AI couldn't fully account for randomness in Gilbert-Elliott channel causing result variations
    \item \textbf{Validation Required}: All AI suggestions needed experimental verification before conclusions
\end{enumerate}

\textbf{Best Practices Identified:}
\begin{itemize}
    \item Provide structured data (CSV) for quantitative analysis
    \item Request specific, actionable recommendations
    \item Iterate: Use initial results to refine queries
    \item Always validate AI suggestions experimentally
\end{itemize}

\end{document}
